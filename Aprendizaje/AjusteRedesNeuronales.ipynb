{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste de redes neuronales \n",
    "\n",
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VR</th>\n",
       "      <th>M</th>\n",
       "      <th>W</th>\n",
       "      <th>H</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>761</td>\n",
       "      <td>41.8</td>\n",
       "      <td>75.2</td>\n",
       "      <td>86.6</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>780</td>\n",
       "      <td>67.4</td>\n",
       "      <td>73.5</td>\n",
       "      <td>66.9</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>44.7</td>\n",
       "      <td>82.9</td>\n",
       "      <td>66.3</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>715</td>\n",
       "      <td>84.7</td>\n",
       "      <td>88.6</td>\n",
       "      <td>78.7</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078</td>\n",
       "      <td>96.7</td>\n",
       "      <td>79.3</td>\n",
       "      <td>76.2</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     VR     M     W     H     P\n",
       "0   761  41.8  75.2  86.6   9.1\n",
       "1   780  67.4  73.5  66.9  17.4\n",
       "2   593  44.7  82.9  66.3  20.0\n",
       "3   715  84.7  88.6  78.7  15.4\n",
       "4  1078  96.7  79.3  76.2  18.2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/alanv/Documents/7/omar/crime_data.csv')\n",
    "df.drop(['State','MR','S'],inplace=True,axis=1)\n",
    "# Dependiente es VR\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare data\n",
    "x = df.iloc[:, 1:].values\n",
    "y = df.iloc[:,0].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    1. Evalúa con validación cruzada un modelo pereceptrón multicapa para las variables que se te asignaron para este ejercicio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  11017.329011130674\n",
      "MAE:  74.44618494694208\n",
      "mse =  501532.82211680186\n",
      "mae =  326.85163386317384\n",
      "mse =  201075.60967884207\n",
      "mae =  283.4168814200769\n",
      "mse =  36654.09200584439\n",
      "mae =  165.92298617690136\n",
      "mse =  92688.12342096666\n",
      "mae =  223.7341728290521\n",
      "mse =  22014.07734081662\n",
      "mae =  118.1156326197759\n",
      "MSE: 170792.9449126543   MAE: 223.608261381796\n"
     ]
    }
   ],
   "source": [
    "#   Multilayer perceptron \n",
    "\n",
    "# Fit regression model using the complete dataset and calculate MSE and MAE\n",
    "regr = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "regr.fit(x, y)\n",
    "\n",
    "y_pred = regr.predict(x)\n",
    "print('MSE: ', mean_squared_error(y, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y, y_pred))\n",
    "\n",
    "# Evaluate regression model using k-fold cross-validation\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "mse_cv = []\n",
    "mae_cv = []\n",
    "for train_index, test_index in kf.split(x):\n",
    "\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    regr_cv = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "    regr_cv.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]    \n",
    "\n",
    "    y_pred = regr_cv.predict(x_test)\n",
    "\n",
    "    # Calculate MSE and MAE\n",
    "\n",
    "    mse_i = mean_squared_error(y_test, y_pred)\n",
    "    print('mse = ', mse_i)  \n",
    "    mse_cv.append(mse_i)    \n",
    "\n",
    "    mae_i = mean_absolute_error(y_test, y_pred)\n",
    "    print('mae = ', mae_i)    \n",
    "    mae_cv.append(mae_i)\n",
    "    \n",
    "   \n",
    "print('MSE:', np.average(mse_cv), '  MAE:', np.average(mae_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Agrega al conjunto de datos columnas que representen los cuadrados de las variables predictoras (por ejemplo, M2, W2), así como los productos entre pares de variables (por ejemplo, PxS, MxW). Evalúa un modelo perceptrón multicapa para este nuevo conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x2 = np.array([df['M'],df['W'],df['H'],df['P'],df['P']**2, df['H']**3,df['W']*df['M'],df['M']*df['P']**2]).T\n",
    "x2 = np.array([df['M'],df['W'],df['H'],df['P'],df['P']**2, df['H']**2,df['W']**2,df['M']**2]).T\n",
    "y2 = np.array(df['VR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  126110.93092449554\n",
      "MAE:  289.0910393419879\n",
      "mse =  197506.67236286792\n",
      "mae =  401.07721179535906\n",
      "mse =  354974.09683260426\n",
      "mae =  362.71752229054766\n",
      "mse =  439590.20785016345\n",
      "mae =  396.71731685927637\n",
      "mse =  55624.218179279895\n",
      "mae =  198.31444760152553\n",
      "mse =  88390.01871564526\n",
      "mae =  247.65618951167343\n",
      "MSE: 227217.04278811216   MAE: 321.2965376116764\n"
     ]
    }
   ],
   "source": [
    "#   Multilayer perceptron square dataset\n",
    "\n",
    "# Fit regression model using the complete dataset and calculate MSE and MAE\n",
    "regr = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "regr.fit(x2, y2)\n",
    "\n",
    "y_pred = regr.predict(x2)\n",
    "print('MSE: ', mean_squared_error(y2, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y2, y_pred))\n",
    "\n",
    "# Evaluate regression model using k-fold cross-validation\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "mse_cv = []\n",
    "mae_cv = []\n",
    "for train_index, test_index in kf.split(x2):\n",
    "\n",
    "    # Training phase\n",
    "    x_train = x2[train_index, :]\n",
    "    y_train = y2[train_index]\n",
    "\n",
    "    regr_cv = MLPRegressor(hidden_layer_sizes=(20, 20), max_iter=20000)\n",
    "    regr_cv.fit(x_train, y_train)\n",
    "\n",
    "    # Test phase\n",
    "    x_test = x2[test_index, :]\n",
    "    y_test = y2[test_index]    \n",
    "\n",
    "    y_pred = regr_cv.predict(x_test)\n",
    "\n",
    "    # Calculate MSE and MAE\n",
    "\n",
    "    mse_i = mean_squared_error(y_test, y_pred)\n",
    "    print('mse = ', mse_i)  \n",
    "    mse_cv.append(mse_i)    \n",
    "\n",
    "    mae_i = mean_absolute_error(y_test, y_pred)\n",
    "    print('mae = ', mae_i)    \n",
    "    mae_cv.append(mae_i)\n",
    "    \n",
    "   \n",
    "print('MSE:', np.average(mse_cv), '  MAE:', np.average(mae_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Viendo los resultados de regresión, desarrolla una conclusión sobre los siguientes puntos:\n",
    "        ¿Consideras que el modelo perceptrón multicapa es efectivo para modelar los datos del problema? ¿Por qué?\n",
    "        ¿Qué modelo es mejor para los datos de criminalidad, el lineal o el perceptrón multicapa? ¿Por qué?\n",
    "No creo que sea un buen modelo, principalmente porque me da errores muy grandes, cuando los datos son relativamente pequeños, y lo que creo que sucede es que no hay suficientes datos para generar un buen modelo o los datos no representan una relación con la variable dependiente. Por lo tanto yo creo que ni el modelo lineal o el perecptron muticapas representan de una manera precisa los datos.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load database\n",
    "df = pd.read_csv('/home/alanv/Documents/7/omar/M_4.txt', delimiter='\\t', header=None)\n",
    "column_names = [f\"V{i}\" for i in range(1, df.shape[1] + 1)]\n",
    "df.columns = column_names\n",
    "df.drop(['V2','V633'],inplace=True,axis=1)\n",
    "# Initializate x and y\n",
    "x = df.iloc[:, 1:].values\n",
    "y = df.iloc[:,0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Evalúa un modelo perceptrón multicapa con validación cruzada utilizando al menos 5 capas de 20 neuronas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.92      0.93        90\n",
      "           2       0.81      0.84      0.83        90\n",
      "           3       0.92      0.89      0.90        90\n",
      "           4       0.88      0.91      0.90        90\n",
      "           5       0.89      0.90      0.90        90\n",
      "           6       0.93      0.84      0.88        90\n",
      "           7       0.86      0.91      0.89        90\n",
      "\n",
      "    accuracy                           0.89       630\n",
      "   macro avg       0.89      0.89      0.89       630\n",
      "weighted avg       0.89      0.89      0.89       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "cv_y_test = []\n",
    "cv_y_pred = []\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    # Training phase\n",
    "    x_train = x[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "    clf_cv = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20), max_iter=10000)\n",
    "    clf_cv.fit(x_train, y_train)\n",
    "    # Test phase\n",
    "    x_test = x[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    y_pred = clf_cv.predict(x_test)\n",
    "    cv_y_test.append(y_test)\n",
    "    cv_y_pred.append(y_pred)\n",
    "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Evalúa un modelo perceptrón multicapa con validación cruzada, pero encontrando el número óptimo de capas y neuronas de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=[70, 70, 70, 70, 70, 70], max_iter=10000)\n"
     ]
    }
   ],
   "source": [
    "# Optimal number of layers and neurons\n",
    "################################################################################\n",
    "num_layers = np.arange(1, 20, 5)\n",
    "num_neurons = np.arange(10, 110, 20)\n",
    "layers = []\n",
    "for l in num_layers:\n",
    "    for n in num_neurons:\n",
    "        layers.append(l*[n])\n",
    "clf = GridSearchCV(MLPClassifier(max_iter=10000), {'hidden_layer_sizes': layers},\n",
    "cv = 5)\n",
    "clf.fit(x, y)\n",
    "print(clf.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. Prepara el modelo perceptrón multicapa:\n",
    "\n",
    "        Opten los hiperparámetros óptimos de capas y neuronas de la red.\n",
    "        Con los hiperparámetros óptimos, ajusta el modelo con todos los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.96        90\n",
      "           2       0.80      0.88      0.84        90\n",
      "           3       0.91      0.83      0.87        90\n",
      "           4       0.88      0.94      0.91        90\n",
      "           5       0.94      0.94      0.94        90\n",
      "           6       0.95      0.86      0.90        90\n",
      "           7       0.90      0.93      0.92        90\n",
      "\n",
      "    accuracy                           0.90       630\n",
      "   macro avg       0.91      0.90      0.91       630\n",
      "weighted avg       0.91      0.90      0.91       630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Evaluate model finding the optimal number of layers and neurons\n",
    "################################################################################\n",
    "clf = MLPClassifier(hidden_layer_sizes=(70, 70, 70, 70, 70, 70), max_iter=10000)\n",
    "y_pred = cross_val_predict(clf, x, y, cv = 5)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Contesta lo siguientes:\n",
    "\n",
    "        ¿Observas alguna mejora importante al optimizar el tamaño de la red? ¿Es el resultado que esperabas? Argumenta tu respuesta.\n",
    "Se observa una mejora, pero no es considerable, aunque era lo que esperaba, ya que al poner 5 capas de 20 neuronas dio un resultado muy bueno. Por lo tanto, pienso que el modelo no tiene mucho más que mejorar.\n",
    "\n",
    "        ¿Qué inconvenientes hay al encontrar el tamaño óptimo de la red? ¿Por qué?\n",
    "El costo computacional puede llegar a ser muy elevado si se quiere probar cada una de las combinaciones de hiperparámetros. Además, se podría ocasionar un sobreajuste y hacer que el modelo no sea preciso con datos nuevos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
